{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/nabeelparuk/south-american-translator-with-keras-nlp-in-prog?scriptVersionId=195813916\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"3dbf3c26","metadata":{"papermill":{"duration":0.020629,"end_time":"2024-09-08T13:23:57.249709","exception":false,"start_time":"2024-09-08T13:23:57.22908","status":"completed"},"tags":[]},"source":["# **South American Translator with Keras NLP**"]},{"cell_type":"code","execution_count":1,"id":"52c2d764","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-09-08T13:23:57.290841Z","iopub.status.busy":"2024-09-08T13:23:57.290449Z","iopub.status.idle":"2024-09-08T13:23:58.157829Z","shell.execute_reply":"2024-09-08T13:23:58.156926Z"},"papermill":{"duration":0.890467,"end_time":"2024-09-08T13:23:58.159969","exception":false,"start_time":"2024-09-08T13:23:57.269502","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/por-eng/por-eng/por.txt\n","/kaggle/input/por-eng/por-eng/_about.txt\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","id":"0e06d09b","metadata":{"papermill":{"duration":0.019883,"end_time":"2024-09-08T13:23:58.200472","exception":false,"start_time":"2024-09-08T13:23:58.180589","status":"completed"},"tags":[]},"source":["## Import modules"]},{"cell_type":"code","execution_count":2,"id":"c47d50e9","metadata":{"execution":{"iopub.execute_input":"2024-09-08T13:23:58.241585Z","iopub.status.busy":"2024-09-08T13:23:58.240844Z","iopub.status.idle":"2024-09-08T13:24:43.030444Z","shell.execute_reply":"2024-09-08T13:24:43.029212Z"},"papermill":{"duration":44.812674,"end_time":"2024-09-08T13:24:43.032864","exception":false,"start_time":"2024-09-08T13:23:58.22019","status":"completed"},"tags":[]},"outputs":[],"source":["!pip install -q --upgrade rouge-score\n","!pip install -q --upgrade keras-nlp\n","!pip install -q --upgrade keras"]},{"cell_type":"code","execution_count":3,"id":"08ac0129","metadata":{"execution":{"iopub.execute_input":"2024-09-08T13:24:43.074792Z","iopub.status.busy":"2024-09-08T13:24:43.074439Z","iopub.status.idle":"2024-09-08T13:24:57.955896Z","shell.execute_reply":"2024-09-08T13:24:57.954982Z"},"papermill":{"duration":14.905182,"end_time":"2024-09-08T13:24:57.958317","exception":false,"start_time":"2024-09-08T13:24:43.053135","status":"completed"},"tags":[]},"outputs":[],"source":["import keras_nlp\n","import pathlib\n","import random\n","import os\n","import pandas as pd\n","import numpy as np\n","\n","import tensorflow as tf\n","import keras\n","from keras import ops\n","\n","import tensorflow.data as tf_data\n","\n","from tensorflow_text.tools.wordpiece_vocab import (\n","    bert_vocab_from_dataset as bert_vocab\n",")\n","\n","import pickle\n","\n","from sklearn.model_selection import train_test_split\n","\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","id":"24bbd01d","metadata":{"papermill":{"duration":0.019745,"end_time":"2024-09-08T13:24:57.998319","exception":false,"start_time":"2024-09-08T13:24:57.978574","status":"completed"},"tags":[]},"source":["# English-Spanish"]},{"cell_type":"markdown","id":"93c9417d","metadata":{"papermill":{"duration":0.01961,"end_time":"2024-09-08T13:24:58.037673","exception":false,"start_time":"2024-09-08T13:24:58.018063","status":"completed"},"tags":[]},"source":["## Setup"]},{"cell_type":"markdown","id":"699efbb7","metadata":{"papermill":{"duration":0.019462,"end_time":"2024-09-08T13:24:58.07805","exception":false,"start_time":"2024-09-08T13:24:58.058588","status":"completed"},"tags":[]},"source":["### Define parameters and hyperparameters"]},{"cell_type":"code","execution_count":4,"id":"abbaa973","metadata":{"execution":{"iopub.execute_input":"2024-09-08T13:24:58.119689Z","iopub.status.busy":"2024-09-08T13:24:58.119066Z","iopub.status.idle":"2024-09-08T13:24:58.124549Z","shell.execute_reply":"2024-09-08T13:24:58.123665Z"},"papermill":{"duration":0.028785,"end_time":"2024-09-08T13:24:58.126669","exception":false,"start_time":"2024-09-08T13:24:58.097884","status":"completed"},"tags":[]},"outputs":[],"source":["MAX_SEQUENCE_LENGTH = 40\n","ENG_VOCAB_SIZE = 15000\n","SPA_VOCAB_SIZE = 15000\n","POR_VOCAB_SIZE = 15000\n","AYM_VOCAB_SIZE = 15000\n","BATCH_SIZE = 64\n","EMBED_DIM = 256\n","INTERMEDIATE_DIM = 2048\n","NUM_HEADS = 8"]},{"cell_type":"markdown","id":"518dab42","metadata":{"papermill":{"duration":0.020049,"end_time":"2024-09-08T13:24:58.166431","exception":false,"start_time":"2024-09-08T13:24:58.146382","status":"completed"},"tags":[]},"source":["### Import English-Spanish Dataset"]},{"cell_type":"code","execution_count":5,"id":"f0cb305d","metadata":{"execution":{"iopub.execute_input":"2024-09-08T13:24:58.208294Z","iopub.status.busy":"2024-09-08T13:24:58.207439Z","iopub.status.idle":"2024-09-08T13:24:58.406387Z","shell.execute_reply":"2024-09-08T13:24:58.405515Z"},"papermill":{"duration":0.222549,"end_time":"2024-09-08T13:24:58.408644","exception":false,"start_time":"2024-09-08T13:24:58.186095","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n","\u001b[1m2638744/2638744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"]}],"source":["text_file = keras.utils.get_file(\n","    fname=\"spa-eng.zip\",\n","    origin=\"http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\",\n","    extract=True\n",")\n","\n","text_file = pathlib.Path(text_file).parent / \"spa-eng\" / \"spa.txt\""]},{"cell_type":"markdown","id":"899ab528","metadata":{"papermill":{"duration":0.020283,"end_time":"2024-09-08T13:24:58.449731","exception":false,"start_time":"2024-09-08T13:24:58.429448","status":"completed"},"tags":[]},"source":["### Parse the data"]},{"cell_type":"markdown","id":"486fe891","metadata":{"papermill":{"duration":0.020039,"end_time":"2024-09-08T13:24:58.490193","exception":false,"start_time":"2024-09-08T13:24:58.470154","status":"completed"},"tags":[]},"source":["* English = Source sequence\n","* Spanish = Target sequence"]},{"cell_type":"code","execution_count":6,"id":"38139228","metadata":{"execution":{"iopub.execute_input":"2024-09-08T13:24:58.532599Z","iopub.status.busy":"2024-09-08T13:24:58.532238Z","iopub.status.idle":"2024-09-08T13:24:58.779832Z","shell.execute_reply":"2024-09-08T13:24:58.779065Z"},"papermill":{"duration":0.271243,"end_time":"2024-09-08T13:24:58.782231","exception":false,"start_time":"2024-09-08T13:24:58.510988","status":"completed"},"tags":[]},"outputs":[],"source":["# We will add the text to a list -> But first make everything lowercase\n","with open(text_file) as f:\n","    lines = f.read().split(\"\\n\")[:-1]\n","text_pairs = []\n","\n","for line in lines:\n","    eng, spa = line.split(\"\\t\")\n","    eng = eng.lower()\n","    spa = spa.lower()\n","    text_pairs.append((eng, spa))"]},{"cell_type":"markdown","id":"f6ecd2ae","metadata":{"papermill":{"duration":0.020404,"end_time":"2024-09-08T13:24:58.823173","exception":false,"start_time":"2024-09-08T13:24:58.802769","status":"completed"},"tags":[]},"source":["#### View the sentence pairs"]},{"cell_type":"code","execution_count":7,"id":"49a2e3c9","metadata":{"execution":{"iopub.execute_input":"2024-09-08T13:24:58.865597Z","iopub.status.busy":"2024-09-08T13:24:58.865235Z","iopub.status.idle":"2024-09-08T13:24:58.869978Z","shell.execute_reply":"2024-09-08T13:24:58.869077Z"},"papermill":{"duration":0.028689,"end_time":"2024-09-08T13:24:58.872389","exception":false,"start_time":"2024-09-08T13:24:58.8437","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["(\"work hard, or you'll have to take the same course again next year.\", 'trabaja duro, o si no, tendrás que tomar el mismo ramo otra vez el año siguiente.')\n","('we took her straight to the clinic as soon as she fainted.', 'cuando ella se desmayó, la llevamos directo a la clínica.')\n","(\"i can't remember ever doing that.\", 'no creo haberlo hecho nunca.')\n","('can you hear us?', '¿puedes oírnos?')\n","('i have a slight fever.', 'tengo un poco de fiebre.')\n"]}],"source":["for _ in range(5):\n","    print(random.choice(text_pairs))"]},{"cell_type":"markdown","id":"e73da713","metadata":{"papermill":{"duration":0.019853,"end_time":"2024-09-08T13:24:58.912402","exception":false,"start_time":"2024-09-08T13:24:58.892549","status":"completed"},"tags":[]},"source":["## Preprocessing"]},{"cell_type":"markdown","id":"b989e4f2","metadata":{"papermill":{"duration":0.019942,"end_time":"2024-09-08T13:24:58.95325","exception":false,"start_time":"2024-09-08T13:24:58.933308","status":"completed"},"tags":[]},"source":["### Split the data"]},{"cell_type":"code","execution_count":8,"id":"2d1764ab","metadata":{"execution":{"iopub.execute_input":"2024-09-08T13:24:58.996691Z","iopub.status.busy":"2024-09-08T13:24:58.995845Z","iopub.status.idle":"2024-09-08T13:24:59.108945Z","shell.execute_reply":"2024-09-08T13:24:59.107841Z"},"papermill":{"duration":0.137189,"end_time":"2024-09-08T13:24:59.111046","exception":false,"start_time":"2024-09-08T13:24:58.973857","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Train size: 83276\n","Validation size: 17844\n","Test size: 17844\n"]}],"source":["# Shuffle the list\n","random.shuffle(text_pairs)\n","\n","# Set training and validation sizes\n","num_val_samples = int(0.15 * len(text_pairs))\n","num_train_samples = int(len(text_pairs) - 2 * num_val_samples)\n","\n","# Get train, val and test sets\n","train_pairs = text_pairs[: num_train_samples]\n","val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n","test_pairs = text_pairs[num_train_samples + num_val_samples :]\n","\n","print(f\"Train size: {len(train_pairs)}\")\n","print(f\"Validation size: {len(val_pairs)}\")\n","print(f\"Test size: {len(test_pairs)}\")"]},{"cell_type":"markdown","id":"894f1e9c","metadata":{"papermill":{"duration":0.02012,"end_time":"2024-09-08T13:24:59.151874","exception":false,"start_time":"2024-09-08T13:24:59.131754","status":"completed"},"tags":[]},"source":["### Tokenization"]},{"cell_type":"markdown","id":"6edbc5e4","metadata":{"papermill":{"duration":0.020068,"end_time":"2024-09-08T13:24:59.192831","exception":false,"start_time":"2024-09-08T13:24:59.172763","status":"completed"},"tags":[]},"source":["We need to define two tokenizers: 1 for the English (source) dataset and one for the Spanish (target) dataset\n","\n","- But first we need to train them on the dataset we have"]},{"cell_type":"markdown","id":"86f82af3","metadata":{"papermill":{"duration":0.020653,"end_time":"2024-09-08T13:24:59.234544","exception":false,"start_time":"2024-09-08T13:24:59.213891","status":"completed"},"tags":[]},"source":["#### Start by generating a vocabulary for each language"]},{"cell_type":"code","execution_count":9,"id":"0f72e2c5","metadata":{"execution":{"iopub.execute_input":"2024-09-08T13:24:59.278865Z","iopub.status.busy":"2024-09-08T13:24:59.278474Z","iopub.status.idle":"2024-09-08T13:24:59.28376Z","shell.execute_reply":"2024-09-08T13:24:59.282877Z"},"papermill":{"duration":0.029777,"end_time":"2024-09-08T13:24:59.285722","exception":false,"start_time":"2024-09-08T13:24:59.255945","status":"completed"},"tags":[]},"outputs":[],"source":["# Use WordPiece to subword tokenize -> returns a vocabulary of subwords\n","def train_word_piece(text_samples, vocab_size, reserved_tokens):\n","    word_piece_ds = tf_data.Dataset.from_tensor_slices(text_samples)\n","    vocab = keras_nlp.tokenizers.compute_word_piece_vocabulary(\n","        word_piece_ds.batch(1000).prefetch(2),\n","        vocabulary_size=vocab_size,\n","    reserved_tokens=reserved_tokens,\n","    )\n","    return vocab"]},{"cell_type":"markdown","id":"7c9574d8","metadata":{"papermill":{"duration":0.020338,"end_time":"2024-09-08T13:24:59.32668","exception":false,"start_time":"2024-09-08T13:24:59.306342","status":"completed"},"tags":[]},"source":["- [PAD] - Padding token\n","- [UNK] - Unknown token\n","- [START] - Token that marks the start of the input sequence\n","- [END] - Token that marks the end of the input sequence"]},{"cell_type":"code","execution_count":10,"id":"b5971cef","metadata":{"execution":{"iopub.execute_input":"2024-09-08T13:24:59.369173Z","iopub.status.busy":"2024-09-08T13:24:59.368815Z","iopub.status.idle":"2024-09-08T13:27:11.914614Z","shell.execute_reply":"2024-09-08T13:27:11.913727Z"},"papermill":{"duration":132.570028,"end_time":"2024-09-08T13:27:11.917218","exception":false,"start_time":"2024-09-08T13:24:59.34719","status":"completed"},"tags":[]},"outputs":[],"source":["# Reserve these tokens\n","reserved_tokens = [\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\"]\n","\n","# Tokenize English samples\n","eng_samples = [text_pair[0] for text_pair in train_pairs]\n","eng_vocab = train_word_piece(eng_samples, ENG_VOCAB_SIZE, reserved_tokens)\n","\n","# Tokenize Spanish samples\n","spa_samples = [text_pair[1] for text_pair in train_pairs]\n","spa_vocab = train_word_piece(spa_samples, SPA_VOCAB_SIZE, reserved_tokens)"]},{"cell_type":"code","execution_count":11,"id":"a4291dfe","metadata":{"execution":{"iopub.execute_input":"2024-09-08T13:27:11.961118Z","iopub.status.busy":"2024-09-08T13:27:11.96005Z","iopub.status.idle":"2024-09-08T13:27:11.965873Z","shell.execute_reply":"2024-09-08T13:27:11.964944Z"},"papermill":{"duration":0.029955,"end_time":"2024-09-08T13:27:11.968131","exception":false,"start_time":"2024-09-08T13:27:11.938176","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["English Tokens:  ['him', 'there', 'go', 'they', 'her', 'has', 'will', 're', 'as', 'time']\n","Spanish Tokens:  ['con', 'le', 'qué', 'ella', 'te', 'mary', 'para', 'las', 'más', 'al']\n"]}],"source":["# View some tokens\n","print(\"English Tokens: \", eng_vocab[100:110])\n","print(\"Spanish Tokens: \", spa_vocab[100:110])"]},{"cell_type":"markdown","id":"c76a7d41","metadata":{"papermill":{"duration":0.020768,"end_time":"2024-09-08T13:27:12.010481","exception":false,"start_time":"2024-09-08T13:27:11.989713","status":"completed"},"tags":[]},"source":["#### Now create the tokenizers with the vocabularies we just made"]},{"cell_type":"code","execution_count":12,"id":"ff82afb6","metadata":{"execution":{"iopub.execute_input":"2024-09-08T13:27:12.052871Z","iopub.status.busy":"2024-09-08T13:27:12.052263Z","iopub.status.idle":"2024-09-08T13:27:12.141442Z","shell.execute_reply":"2024-09-08T13:27:12.140445Z"},"papermill":{"duration":0.112708,"end_time":"2024-09-08T13:27:12.14364","exception":false,"start_time":"2024-09-08T13:27:12.030932","status":"completed"},"tags":[]},"outputs":[],"source":["# English tokenizer\n","eng_tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n","    vocabulary=eng_vocab, lowercase=False\n",")\n","\n","# Spanish tokenizer\n","spa_tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n","    vocabulary=spa_vocab, lowercase=False\n",")"]},{"cell_type":"code","execution_count":13,"id":"403ebb7d","metadata":{"execution":{"iopub.execute_input":"2024-09-08T13:27:12.186169Z","iopub.status.busy":"2024-09-08T13:27:12.185811Z","iopub.status.idle":"2024-09-08T13:27:12.206624Z","shell.execute_reply":"2024-09-08T13:27:12.205906Z"},"papermill":{"duration":0.044045,"end_time":"2024-09-08T13:27:12.208573","exception":false,"start_time":"2024-09-08T13:27:12.164528","status":"completed"},"tags":[]},"outputs":[],"source":["# Save tokenizers to file\n","# English\n","with open('tokenizer_engspa_eng.pickle', 'wb') as handle:\n","    pickle.dump(eng_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","    \n","# Spanish\n","with open('tokenizer_engspa_spa.pickle', 'wb') as handle:\n","    pickle.dump(spa_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"]},{"cell_type":"code","execution_count":14,"id":"32374aac","metadata":{"execution":{"iopub.execute_input":"2024-09-08T13:27:12.250837Z","iopub.status.busy":"2024-09-08T13:27:12.250484Z","iopub.status.idle":"2024-09-08T13:27:12.383261Z","shell.execute_reply":"2024-09-08T13:27:12.382005Z"},"papermill":{"duration":0.156677,"end_time":"2024-09-08T13:27:12.385938","exception":false,"start_time":"2024-09-08T13:27:12.229261","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["English Sentence:  the animal struggled to get out of the cage.\n","Tokens:  tf.Tensor([  64 1332   45  335  505 2957   65  122  121   72   64 2531   12], shape=(13,), dtype=int32)\n","Recovered text after detokenizing:  tf.Tensor(b'the animal struggled to get out of the cage .', shape=(), dtype=string)\n","\n","Spanish sentence:  el animal luchó por salir de la jaula.\n","Tokens:  tf.Tensor([  85 1689   41 1315 1906   92  350   80   84 3162   15], shape=(11,), dtype=int32)\n","Recovered text after detokenizing: tf.Tensor(b'el animal luch\\xc3\\xb3 por salir de la jaula .', shape=(), dtype=string)\n"]}],"source":["# Lets test the tokenizers on a sample\n","# English\n","eng_input_eg = text_pairs[0][0]\n","eng_tokens_eg = eng_tokenizer.tokenize(eng_input_eg)\n","print(\"English Sentence: \", eng_input_eg)\n","print(\"Tokens: \", eng_tokens_eg)\n","print(\"Recovered text after detokenizing: \",\n","     eng_tokenizer.detokenize(eng_tokens_eg))\n","\n","print()\n","# Spanish\n","spa_input_eg = text_pairs[0][1]\n","spa_tokens_eg = spa_tokenizer.tokenize(spa_input_eg)\n","print(\"Spanish sentence: \", spa_input_eg)\n","print(\"Tokens: \", spa_tokens_eg)\n","print(\"Recovered text after detokenizing:\",\n","     spa_tokenizer.detokenize(spa_tokens_eg))"]},{"cell_type":"markdown","id":"e1c6e92c","metadata":{"papermill":{"duration":0.023385,"end_time":"2024-09-08T13:27:12.434349","exception":false,"start_time":"2024-09-08T13:27:12.410964","status":"completed"},"tags":[]},"source":["### Format datasets"]},{"cell_type":"markdown","id":"e723b876","metadata":{"papermill":{"duration":0.060629,"end_time":"2024-09-08T13:27:12.518286","exception":false,"start_time":"2024-09-08T13:27:12.457657","status":"completed"},"tags":[]},"source":["**We want the model to predict target words N+1 and beyond using:**\n"," - The source sentence (English)\n"," - The words up to N (words already predicted before)\n"," \n","**The training dataset will yield a tuple (inputs, targets):**\n"," -  Inputs: Dictionary with keys `encoder_inputs` and `decoder_inputs`.\n","     - `encoder_inputs` -> Tokenized source sentence\n","     - `decoder_inputs` -> Target sentence so far (what has already been predicted i.e. words up to N\n"," - Targets: target sentence offset by one step\n","     - Provides the next words in the target sentence (what the model will try to predict\n","\n","We also need to add special tokens ([START] and [END]) to the input Spanish sentence after tokenizing the text AND we need to pad input to a fixed length\n"," - This can be done using `keras_nlp.layers.StartEndPacker`"]},{"cell_type":"code","execution_count":15,"id":"c9a7dd89","metadata":{"execution":{"iopub.execute_input":"2024-09-08T13:27:12.560995Z","iopub.status.busy":"2024-09-08T13:27:12.560288Z","iopub.status.idle":"2024-09-08T13:27:12.568039Z","shell.execute_reply":"2024-09-08T13:27:12.566989Z"},"papermill":{"duration":0.031322,"end_time":"2024-09-08T13:27:12.570126","exception":false,"start_time":"2024-09-08T13:27:12.538804","status":"completed"},"tags":[]},"outputs":[],"source":["# Define the preprocessing function\n","def preprocess_batch(eng, spa):\n","    # Batch size depending on the length of the tokens\n","    batch_size = ops.shape(spa)[0]\n","    \n","    # Tokenize\n","    eng = eng_tokenizer(eng)\n","    spa = spa_tokenizer(spa)\n","    \n","    # Pad the English tokenized data to 'MAX_SEQUENCE_LENGTH'\n","    eng_start_end_packer = keras_nlp.layers.StartEndPacker(\n","        sequence_length=MAX_SEQUENCE_LENGTH,\n","        pad_value=eng_tokenizer.token_to_id(\"[PAD]\"),\n","    )\n","    eng = eng_start_end_packer(eng)\n","    \n","    # Pad the Spanish tokenized data AND add special tokens '[START]' and '[END]'\n","    spa_start_end_packer = keras_nlp.layers.StartEndPacker(\n","        sequence_length=MAX_SEQUENCE_LENGTH + 1,\n","        start_value=spa_tokenizer.token_to_id(\"[START]\"),\n","        end_value=spa_tokenizer.token_to_id(\"[END]\"),\n","        pad_value=spa_tokenizer.token_to_id(\"[PAD]\"),\n","    )\n","    spa = spa_start_end_packer(spa)\n","    \n","    # Now return the tuple with the inputs (encoder inputs and decoder inputs in a dictionary) and the targets\n","    return (\n","        {\n","            \"encoder_inputs\": eng,\n","            \"decoder_inputs\": spa[ : , :-1]\n","        },\n","        spa[:, 1:],\n","    )"]},{"cell_type":"code","execution_count":16,"id":"db2ad202","metadata":{"execution":{"iopub.execute_input":"2024-09-08T13:27:12.612935Z","iopub.status.busy":"2024-09-08T13:27:12.612189Z","iopub.status.idle":"2024-09-08T13:27:12.618261Z","shell.execute_reply":"2024-09-08T13:27:12.617359Z"},"papermill":{"duration":0.029903,"end_time":"2024-09-08T13:27:12.620278","exception":false,"start_time":"2024-09-08T13:27:12.590375","status":"completed"},"tags":[]},"outputs":[],"source":["# Define the dataset function\n","def make_dataset(pairs):\n","    \n","    # Get the texts for each language individually\n","    eng_texts, spa_texts = zip(*pairs)\n","    \n","    # Turn returned variables into lists\n","    eng_texts = list(eng_texts)\n","    spa_texts = list(spa_texts)\n","    \n","    # Turn it into a tf_data dataset\n","    dataset = tf_data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n","    dataset = dataset.batch(BATCH_SIZE)\n","    dataset = dataset.map(preprocess_batch, num_parallel_calls=tf_data.AUTOTUNE)\n","    \n","    return dataset.shuffle(2048).prefetch(16).cache()"]},{"cell_type":"code","execution_count":17,"id":"b54ba2a4","metadata":{"execution":{"iopub.execute_input":"2024-09-08T13:27:12.66318Z","iopub.status.busy":"2024-09-08T13:27:12.662418Z","iopub.status.idle":"2024-09-08T13:27:15.685469Z","shell.execute_reply":"2024-09-08T13:27:15.684456Z"},"papermill":{"duration":3.04702,"end_time":"2024-09-08T13:27:15.68783","exception":false,"start_time":"2024-09-08T13:27:12.64081","status":"completed"},"tags":[]},"outputs":[],"source":["# Create the dataset\n","train_ds = make_dataset(train_pairs)\n","val_ds = make_dataset(val_pairs)"]},{"cell_type":"code","execution_count":18,"id":"c0b919ad","metadata":{"execution":{"iopub.execute_input":"2024-09-08T13:27:15.7315Z","iopub.status.busy":"2024-09-08T13:27:15.730648Z","iopub.status.idle":"2024-09-08T13:27:16.778862Z","shell.execute_reply":"2024-09-08T13:27:16.777925Z"},"papermill":{"duration":1.07273,"end_time":"2024-09-08T13:27:16.781264","exception":false,"start_time":"2024-09-08T13:27:15.708534","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["inputs[\"encoder_inputs\"].shape: (64, 40)\n","inputs[\"decoder_inputs\"].shape: (64, 40)\n","targets.shape: (64, 40)\n"]}],"source":["# Look at sequence shapes\n","for inputs, targets in train_ds.take(1):\n","    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n","    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n","    print(f\"targets.shape: {targets.shape}\")"]},{"cell_type":"markdown","id":"0e5101eb","metadata":{"papermill":{"duration":0.020803,"end_time":"2024-09-08T13:27:16.823426","exception":false,"start_time":"2024-09-08T13:27:16.802623","status":"completed"},"tags":[]},"source":["## Model Construction"]},{"cell_type":"markdown","id":"093046b9","metadata":{"papermill":{"duration":0.021318,"end_time":"2024-09-08T13:27:16.865798","exception":false,"start_time":"2024-09-08T13:27:16.84448","status":"completed"},"tags":[]},"source":["**We need:**\n","- Embeddings -> The following are combined into one layer\n","    - Embedding layer\n","        - Creates a vector for every token in our sequence\n","        - Can be initialised randomly\n","    - Positional embedding layer\n","        - Encodes the word order in the sequence\n","        - With the `mask_zero` argument we can mask the padding tokens (\"[PAD]\")\n","- Seq2Seq Transformer\n","    - Consists of `TransformerEncoder` and `TransformerDecoder` layers chained together"]},{"cell_type":"markdown","id":"af69ecb3","metadata":{"papermill":{"duration":0.020814,"end_time":"2024-09-08T13:27:16.907493","exception":false,"start_time":"2024-09-08T13:27:16.886679","status":"completed"},"tags":[]},"source":["**Workflow of model:**\n","1. Source sequence (English) passes to `TransformerEncoder` -> produces a new representation of it\n","2. New representation passed to `TransformerDecoder`\n","3. With the target sequence so far (what has previously been predicted from 0 to N) and `TransformerDecoder`, the new representation is used to predict the N+1th word."]},{"cell_type":"markdown","id":"373c6014","metadata":{"papermill":{"duration":0.021336,"end_time":"2024-09-08T13:27:16.949381","exception":false,"start_time":"2024-09-08T13:27:16.928045","status":"completed"},"tags":[]},"source":["**Key detail: Causal Masking**\n","- `TransformerDecoder` sees the whole sequence at once but we only want information from target tokens 0 to N when predicting N + 1\n","- Using information from the future would result in a model that can't be used in inference time"]},{"cell_type":"markdown","id":"6409fea2","metadata":{"papermill":{"duration":0.020683,"end_time":"2024-09-08T13:27:16.99192","exception":false,"start_time":"2024-09-08T13:27:16.971237","status":"completed"},"tags":[]},"source":["### Create modelling checkpoint callback"]},{"cell_type":"code","execution_count":19,"id":"1c0c8d8a","metadata":{"execution":{"iopub.execute_input":"2024-09-08T13:27:17.035292Z","iopub.status.busy":"2024-09-08T13:27:17.034472Z","iopub.status.idle":"2024-09-08T13:27:17.039712Z","shell.execute_reply":"2024-09-08T13:27:17.038833Z"},"papermill":{"duration":0.028796,"end_time":"2024-09-08T13:27:17.041708","exception":false,"start_time":"2024-09-08T13:27:17.012912","status":"completed"},"tags":[]},"outputs":[],"source":["def create_model_checkpoint(model_name, save_path=\"/kaggle/working/model_experiments\"):\n","    return tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(save_path, f\"{model_name}.keras\"),\n","                                            verbose=0,\n","                                            save_best_only=True)"]},{"cell_type":"markdown","id":"68c8033d","metadata":{"papermill":{"duration":0.020886,"end_time":"2024-09-08T13:27:17.083038","exception":false,"start_time":"2024-09-08T13:27:17.062152","status":"completed"},"tags":[]},"source":["### Encoder"]},{"cell_type":"code","execution_count":20,"id":"cfcb0802","metadata":{"execution":{"iopub.execute_input":"2024-09-08T13:27:17.127322Z","iopub.status.busy":"2024-09-08T13:27:17.126964Z","iopub.status.idle":"2024-09-08T13:27:18.430691Z","shell.execute_reply":"2024-09-08T13:27:18.429918Z"},"papermill":{"duration":1.328746,"end_time":"2024-09-08T13:27:18.433136","exception":false,"start_time":"2024-09-08T13:27:17.10439","status":"completed"},"tags":[]},"outputs":[],"source":["# Use Functional API\n","# Inputs\n","encoder_inputs = keras.Input(shape=(None,), name=\"encoder_inputs\")\n","\n","# Embedding\n","x = keras_nlp.layers.TokenAndPositionEmbedding(\n","    vocabulary_size=ENG_VOCAB_SIZE,\n","    sequence_length=MAX_SEQUENCE_LENGTH,\n","    embedding_dim=EMBED_DIM\n",")(encoder_inputs)\n","\n","# Outputs\n","encoder_outputs = keras_nlp.layers.TransformerEncoder(\n","    intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS\n",")(inputs=x)\n","\n","# Define encoder\n","encoder = keras.Model(encoder_inputs, encoder_outputs)"]},{"cell_type":"markdown","id":"3a79d20e","metadata":{"papermill":{"duration":0.0205,"end_time":"2024-09-08T13:27:18.47447","exception":false,"start_time":"2024-09-08T13:27:18.45397","status":"completed"},"tags":[]},"source":["### Decoder"]},{"cell_type":"code","execution_count":21,"id":"b149dd5b","metadata":{"execution":{"iopub.execute_input":"2024-09-08T13:27:18.517455Z","iopub.status.busy":"2024-09-08T13:27:18.517093Z","iopub.status.idle":"2024-09-08T13:27:18.63003Z","shell.execute_reply":"2024-09-08T13:27:18.629066Z"},"papermill":{"duration":0.13684,"end_time":"2024-09-08T13:27:18.632282","exception":false,"start_time":"2024-09-08T13:27:18.495442","status":"completed"},"tags":[]},"outputs":[],"source":["# Use Functional API\n","# Inputs\n","decoder_inputs = keras.Input(shape=(None,), name=\"decoder_inputs\") # What has been predicted\n","encoded_seq_inputs = keras.Input(shape=(None, EMBED_DIM), name=\"decoder_state_inputs\") # Output from encoder\n","\n","# Embedding\n","x = keras_nlp.layers.TokenAndPositionEmbedding(\n","    vocabulary_size=SPA_VOCAB_SIZE,\n","    sequence_length=MAX_SEQUENCE_LENGTH,\n","    embedding_dim=EMBED_DIM,\n",")(decoder_inputs)\n","\n","# Decoder layer\n","x = keras_nlp.layers.TransformerDecoder(\n","    intermediate_dim=INTERMEDIATE_DIM,\n","    num_heads=NUM_HEADS\n",")(decoder_sequence=x, encoder_sequence=encoded_seq_inputs)\n","\n","# Add dropout\n","x = keras.layers.Dropout(0.5)(x)\n","\n","# Outputs\n","decoder_outputs = keras.layers.Dense(SPA_VOCAB_SIZE, activation='softmax')(x)\n","\n","# Define decoder\n","decoder = keras.Model(\n","    [\n","    decoder_inputs,\n","    encoded_seq_inputs,\n","    ],\n","    decoder_outputs\n",")\n","\n","decoder_outputs = decoder([decoder_inputs, encoder_outputs])"]},{"cell_type":"markdown","id":"43906d1c","metadata":{"papermill":{"duration":0.020228,"end_time":"2024-09-08T13:27:18.673166","exception":false,"start_time":"2024-09-08T13:27:18.652938","status":"completed"},"tags":[]},"source":["### Transformer"]},{"cell_type":"code","execution_count":22,"id":"8c6883da","metadata":{"execution":{"iopub.execute_input":"2024-09-08T13:27:18.715777Z","iopub.status.busy":"2024-09-08T13:27:18.715142Z","iopub.status.idle":"2024-09-08T13:27:18.741273Z","shell.execute_reply":"2024-09-08T13:27:18.740375Z"},"papermill":{"duration":0.049606,"end_time":"2024-09-08T13:27:18.743093","exception":false,"start_time":"2024-09-08T13:27:18.693487","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer_eng_spa\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"transformer_eng_spa\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ token_and_position… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,850,240</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenAndPositionE…</span> │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ transformer_encoder │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,315,072</span> │ token_and_positi… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ functional_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">9,283,992</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">15000</span>)            │            │ transformer_enco… │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ token_and_position… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,850,240\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n","│ (\u001b[38;5;33mTokenAndPositionE…\u001b[0m │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ decoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ transformer_encoder │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m1,315,072\u001b[0m │ token_and_positi… │\n","│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ functional_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │  \u001b[38;5;34m9,283,992\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n","│ (\u001b[38;5;33mFunctional\u001b[0m)        │ \u001b[38;5;34m15000\u001b[0m)            │            │ transformer_enco… │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,449,304</span> (55.12 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,449,304\u001b[0m (55.12 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,449,304</span> (55.12 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m14,449,304\u001b[0m (55.12 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"}],"source":["transformer1 = keras.Model(\n","    [encoder_inputs, decoder_inputs],\n","    decoder_outputs,\n","    name=\"transformer_eng_spa\"\n",")\n","\n","transformer1.summary()"]},{"cell_type":"code","execution_count":23,"id":"b6471cc2","metadata":{"execution":{"iopub.execute_input":"2024-09-08T13:27:18.786524Z","iopub.status.busy":"2024-09-08T13:27:18.786208Z","iopub.status.idle":"2024-09-08T13:27:18.798925Z","shell.execute_reply":"2024-09-08T13:27:18.798042Z"},"papermill":{"duration":0.036743,"end_time":"2024-09-08T13:27:18.800934","exception":false,"start_time":"2024-09-08T13:27:18.764191","status":"completed"},"tags":[]},"outputs":[],"source":["# Compile transformer\n","transformer1.compile(optimizer=tf.keras.optimizers.RMSprop(),\n","                   loss=\"sparse_categorical_crossentropy\",\n","                   metrics=['accuracy'])"]},{"cell_type":"markdown","id":"bc78d4c7","metadata":{"papermill":{"duration":0.021132,"end_time":"2024-09-08T13:27:18.843386","exception":false,"start_time":"2024-09-08T13:27:18.822254","status":"completed"},"tags":[]},"source":["### Train Model"]},{"cell_type":"code","execution_count":24,"id":"ec24402c","metadata":{"execution":{"iopub.execute_input":"2024-09-08T13:27:18.88799Z","iopub.status.busy":"2024-09-08T13:27:18.88756Z","iopub.status.idle":"2024-09-08T13:34:01.572442Z","shell.execute_reply":"2024-09-08T13:34:01.57143Z"},"papermill":{"duration":403.014283,"end_time":"2024-09-08T13:34:01.879214","exception":false,"start_time":"2024-09-08T13:27:18.864931","status":"completed"},"scrolled":true,"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1725802045.492484      88 service.cc:145] XLA service 0x7b3cfc0223d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","I0000 00:00:1725802045.492534      88 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","I0000 00:00:1725802045.492538      88 service.cc:153]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n","W0000 00:00:1725802045.878947      88 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1725802052.377795     180 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_117', 8 bytes spill stores, 8 bytes spill loads\n","\n","I0000 00:00:1725802055.576088     179 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_117', 968 bytes spill stores, 924 bytes spill loads\n","\n","I0000 00:00:1725802056.344830     178 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_115', 256 bytes spill stores, 256 bytes spill loads\n","\n","I0000 00:00:1725802065.195987     181 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_120', 4 bytes spill stores, 4 bytes spill loads\n","\n","I0000 00:00:1725802065.801880     179 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_112', 256 bytes spill stores, 256 bytes spill loads\n","\n","I0000 00:00:1725802066.862066     180 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_22', 864 bytes spill stores, 864 bytes spill loads\n","\n","I0000 00:00:1725802071.551319     178 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_120', 968 bytes spill stores, 924 bytes spill loads\n","\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m   2/1302\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:42\u001b[0m 79ms/step - accuracy: 0.1949 - loss: 9.0760       "]},{"name":"stderr","output_type":"stream","text":["I0000 00:00:1725802077.429699      88 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m 599/1302\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 48ms/step - accuracy: 0.7782 - loss: 1.9383"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1725802106.661801      87 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n","I0000 00:00:1725802119.183976     256 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_117', 1764 bytes spill stores, 1768 bytes spill loads\n","\n","I0000 00:00:1725802123.954671     253 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_120', 1764 bytes spill stores, 1768 bytes spill loads\n","\n","I0000 00:00:1725802124.989100     254 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_22', 864 bytes spill stores, 864 bytes spill loads\n","\n","I0000 00:00:1725802127.031702     255 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_115', 340 bytes spill stores, 340 bytes spill loads\n","\n","I0000 00:00:1725802128.545267     256 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_112', 100 bytes spill stores, 100 bytes spill loads\n","\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8230 - loss: 1.4396"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1725802167.591437      89 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n","W0000 00:00:1725802171.401634      90 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n","I0000 00:00:1725802179.218304     319 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_21', 100 bytes spill stores, 100 bytes spill loads\n","\n","I0000 00:00:1725802179.395902     320 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_24', 340 bytes spill stores, 340 bytes spill loads\n","\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 81ms/step - accuracy: 0.8230 - loss: 1.4391 - val_accuracy: 0.9842 - val_loss: 0.1406\n","Epoch 2/5\n","\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 51ms/step - accuracy: 0.9872 - loss: 0.1071 - val_accuracy: 0.9998 - val_loss: 0.0087\n","Epoch 3/5\n","\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 50ms/step - accuracy: 0.9992 - loss: 0.0123 - val_accuracy: 0.9999 - val_loss: 9.8450e-04\n","Epoch 4/5\n","\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 50ms/step - accuracy: 0.9997 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 4.2457e-04\n","Epoch 5/5\n","\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 8.0089e-04 - val_accuracy: 1.0000 - val_loss: 1.7282e-04\n"]},{"data":{"text/plain":["<keras.src.callbacks.history.History at 0x7b3d641a3a90>"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["transformer1.fit(train_ds,\n","                validation_data=val_ds,\n","                epochs=5,\n","                callbacks=[create_model_checkpoint(transformer1.name)]\n","               )"]},{"cell_type":"markdown","id":"4cd4d47b","metadata":{"papermill":{"duration":0.303778,"end_time":"2024-09-08T13:34:02.528461","exception":false,"start_time":"2024-09-08T13:34:02.224683","status":"completed"},"tags":[]},"source":["## Decoding Test Sentences"]},{"cell_type":"markdown","id":"79ec890d","metadata":{"papermill":{"duration":0.30702,"end_time":"2024-09-08T13:34:03.14217","exception":false,"start_time":"2024-09-08T13:34:02.83515","status":"completed"},"tags":[]},"source":["Use this section to translate brand new test sentences"]},{"cell_type":"code","execution_count":25,"id":"84107413","metadata":{"execution":{"iopub.execute_input":"2024-09-08T13:34:03.753106Z","iopub.status.busy":"2024-09-08T13:34:03.75226Z","iopub.status.idle":"2024-09-08T13:34:03.761901Z","shell.execute_reply":"2024-09-08T13:34:03.760842Z"},"papermill":{"duration":0.317212,"end_time":"2024-09-08T13:34:03.763772","exception":false,"start_time":"2024-09-08T13:34:03.44656","status":"completed"},"tags":[]},"outputs":[],"source":["def decode_sequences(input_sentences, transformer, lan_tokenizer):\n","    batch_size = 1\n","    \n","    # Tokenize encoder input\n","    encoder_input_tokens = ops.convert_to_tensor(eng_tokenizer(input_sentences))\n","    if len(encoder_input_tokens[0]) < MAX_SEQUENCE_LENGTH:\n","        pads = ops.full((1, MAX_SEQUENCE_LENGTH - len(encoder_input_tokens[0])), 0)\n","        encoder_input_tokens = ops.concatenate(\n","            [encoder_input_tokens.to_tensor(), pads], 1\n","        )\n","        \n","    # Define a function that outputs the next tokens probability given the input sequence\n","    def next(prompt, cache, index):\n","        logits = transformer([encoder_input_tokens, prompt])[:, index - 1, :]\n","        # We ignore hidden states for now -> needed only for contrastive search\n","        hidden_states = None\n","        return logits, hidden_states, cache\n","    \n","    # Build a prompt of length 40 with a start token and padding tokens\n","    length = 40\n","    # Add start token\n","    start = ops.full((batch_size, 1), lan_tokenizer.token_to_id(\"[START]\"))\n","    # Add pad token\n","    pad = ops.full((batch_size, length - 1), lan_tokenizer.token_to_id(\"[PAD]\"))\n","    \n","    prompt = ops.concatenate((start, pad), axis=-1)\n","    \n","    # GreedySampler -> Outputs token with highest probability\n","    generated_tokens = keras_nlp.samplers.GreedySampler()(\n","        next,\n","        prompt,\n","        stop_token_ids=[lan_tokenizer.token_to_id(\"[END]\")],\n","        index=1, # Sample only after \"[START]\" token\n","    )\n","    generated_sentences = lan_tokenizer.detokenize(generated_tokens)\n","    return generated_sentences"]},{"cell_type":"code","execution_count":26,"id":"424dd611","metadata":{"execution":{"iopub.execute_input":"2024-09-08T13:34:04.413483Z","iopub.status.busy":"2024-09-08T13:34:04.412592Z","iopub.status.idle":"2024-09-08T13:34:11.487745Z","shell.execute_reply":"2024-09-08T13:34:11.486826Z"},"papermill":{"duration":7.421282,"end_time":"2024-09-08T13:34:11.490056","exception":false,"start_time":"2024-09-08T13:34:04.068774","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Example 1\n","he married a very pretty girl.\n","nombre : estoy ido leer +\n","\n","Example 2\n","tom's coming.\n","mando p estaban +\n","\n"]}],"source":["# Draw English samples from test set\n","test_eng_texts = [pair[0] for pair in test_pairs]\n","\n","for i in range(2):\n","    input_sentence = random.choice(test_eng_texts)\n","    translated = decode_sequences([input_sentence], transformer1, spa_tokenizer)\n","    translated = translated.numpy()[0].decode(\"utf-8\")\n","    \n","    translated = (\n","        translated.replace(\"[PAD]\",\"\")\n","        .replace(\"[START]\",\"\")\n","        .replace(\"[END]\", \"\")\n","        .strip()\n","    )\n","    print(f\"Example {i+1}\")\n","    print(input_sentence)\n","    print(translated)\n","    print()"]},{"cell_type":"markdown","id":"9d25161b","metadata":{"papermill":{"duration":0.307022,"end_time":"2024-09-08T13:34:12.098441","exception":false,"start_time":"2024-09-08T13:34:11.791419","status":"completed"},"tags":[]},"source":["## Evaluate model"]},{"cell_type":"markdown","id":"c9ffc927","metadata":{"papermill":{"duration":0.305,"end_time":"2024-09-08T13:34:12.706226","exception":false,"start_time":"2024-09-08T13:34:12.401226","status":"completed"},"tags":[]},"source":["We are going to use the METEOR score metric to conduct a quantitative analysis of our model"]},{"cell_type":"code","execution_count":null,"id":"8cb4fee9","metadata":{"papermill":{"duration":0.303335,"end_time":"2024-09-08T13:34:13.313179","exception":false,"start_time":"2024-09-08T13:34:13.009844","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"markdown","id":"ccf0e862","metadata":{"papermill":{"duration":0.304301,"end_time":"2024-09-08T13:34:13.962914","exception":false,"start_time":"2024-09-08T13:34:13.658613","status":"completed"},"tags":[]},"source":["# English-Portuguese"]},{"cell_type":"markdown","id":"793c5b3f","metadata":{"papermill":{"duration":0.303744,"end_time":"2024-09-08T13:34:14.569377","exception":false,"start_time":"2024-09-08T13:34:14.265633","status":"completed"},"tags":[]},"source":["## Setup"]},{"cell_type":"markdown","id":"ffbbfdb6","metadata":{"papermill":{"duration":0.30729,"end_time":"2024-09-08T13:34:15.179192","exception":false,"start_time":"2024-09-08T13:34:14.871902","status":"completed"},"tags":[]},"source":["#### Parse the data"]},{"cell_type":"code","execution_count":27,"id":"a852dbbb","metadata":{"execution":{"iopub.execute_input":"2024-09-08T13:34:15.829036Z","iopub.status.busy":"2024-09-08T13:34:15.82825Z","iopub.status.idle":"2024-09-08T13:34:16.650856Z","shell.execute_reply":"2024-09-08T13:34:16.649857Z"},"papermill":{"duration":1.170199,"end_time":"2024-09-08T13:34:16.653104","exception":false,"start_time":"2024-09-08T13:34:15.482905","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Go.</td>\n","      <td>Vai.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Go.</td>\n","      <td>Vá.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Hi.</td>\n","      <td>Oi.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Run!</td>\n","      <td>Corre!</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Run!</td>\n","      <td>Corra!</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      0       1\n","0   Go.    Vai.\n","1   Go.     Vá.\n","2   Hi.     Oi.\n","3  Run!  Corre!\n","4  Run!  Corra!"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["por_eng_df = pd.read_csv('/kaggle/input/por-eng/por-eng/por.txt', header=None, sep=\"\\t\")\n","por_eng_df = por_eng_df.loc[: , :1]\n","por_eng_df.head()"]},{"cell_type":"code","execution_count":28,"id":"0b8ba662","metadata":{"execution":{"iopub.execute_input":"2024-09-08T13:34:17.269288Z","iopub.status.busy":"2024-09-08T13:34:17.268663Z","iopub.status.idle":"2024-09-08T13:34:17.499034Z","shell.execute_reply":"2024-09-08T13:34:17.498233Z"},"papermill":{"duration":0.543379,"end_time":"2024-09-08T13:34:17.501299","exception":false,"start_time":"2024-09-08T13:34:16.95792","status":"completed"},"tags":[]},"outputs":[],"source":["# Create lists from each data\n","eng_list = por_eng_df.loc[:,0].to_list()\n","por_list = por_eng_df.loc[:,1].to_list()\n","\n","text_pairs = []\n","\n","# Iterate over list and lowercase\n","for i in range(len(eng_list)):\n","    eng = eng_list[i].lower()\n","    por = por_list[i].lower()\n","    \n","    text_pairs.append((eng, por))"]},{"cell_type":"markdown","id":"91c5d1ed","metadata":{"papermill":{"duration":0.301957,"end_time":"2024-09-08T13:34:18.106919","exception":false,"start_time":"2024-09-08T13:34:17.804962","status":"completed"},"tags":[]},"source":["##### View the sentence pairs"]},{"cell_type":"code","execution_count":29,"id":"a687e398","metadata":{"execution":{"iopub.execute_input":"2024-09-08T13:34:18.715929Z","iopub.status.busy":"2024-09-08T13:34:18.714961Z","iopub.status.idle":"2024-09-08T13:34:18.720483Z","shell.execute_reply":"2024-09-08T13:34:18.719593Z"},"papermill":{"duration":0.313282,"end_time":"2024-09-08T13:34:18.722673","exception":false,"start_time":"2024-09-08T13:34:18.409391","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["('my husband is a doctor.', 'o meu marido é médico.')\n","('please iron the shirt.', 'passe a camisa, por favor.')\n","(\"i'm not a baby.\", 'eu não sou um bebê.')\n","('we wanted it to be a surprise.', 'nós queríamos que fosse uma surpresa.')\n","(\"i pray that you'll have the best of luck.\", 'oro para que você tenha a melhor sorte.')\n"]}],"source":["for _ in range(5):\n","    print(random.choice(text_pairs))"]},{"cell_type":"markdown","id":"7882bbdf","metadata":{"papermill":{"duration":0.301985,"end_time":"2024-09-08T13:34:19.372547","exception":false,"start_time":"2024-09-08T13:34:19.070562","status":"completed"},"tags":[]},"source":["## Preprocessing"]},{"cell_type":"markdown","id":"0005de32","metadata":{"papermill":{"duration":0.300146,"end_time":"2024-09-08T13:34:19.974554","exception":false,"start_time":"2024-09-08T13:34:19.674408","status":"completed"},"tags":[]},"source":["### Split the data"]},{"cell_type":"code","execution_count":30,"id":"24db2260","metadata":{"execution":{"iopub.execute_input":"2024-09-08T13:34:20.583004Z","iopub.status.busy":"2024-09-08T13:34:20.582122Z","iopub.status.idle":"2024-09-08T13:34:20.791454Z","shell.execute_reply":"2024-09-08T13:34:20.789165Z"},"papermill":{"duration":0.516928,"end_time":"2024-09-08T13:34:20.79523","exception":false,"start_time":"2024-09-08T13:34:20.278302","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Train size: 135545\n","Validation size: 29044\n","Test size: 29044\n"]}],"source":["random.shuffle(text_pairs)\n","\n","# Set training and validation sizes\n","num_val_samples = int(0.15 * len(text_pairs))\n","num_train_samples = int(len(text_pairs) - 2 * num_val_samples)\n","\n","# Get train, val and test sets\n","train_pairs = text_pairs[: num_train_samples]\n","val_pairs = text_pairs[num_train_samples:num_train_samples + num_val_samples]\n","test_pairs = text_pairs[num_train_samples + num_val_samples:]\n","\n","print(f\"Train size: {len(train_pairs)}\")\n","print(f\"Validation size: {len(val_pairs)}\")\n","print(f\"Test size: {len(test_pairs)}\")"]},{"cell_type":"markdown","id":"1f7648a5","metadata":{"papermill":{"duration":0.355538,"end_time":"2024-09-08T13:34:21.501796","exception":false,"start_time":"2024-09-08T13:34:21.146258","status":"completed"},"tags":[]},"source":["### Tokenization"]},{"cell_type":"code","execution_count":31,"id":"0f1b01d9","metadata":{"execution":{"iopub.execute_input":"2024-09-08T13:34:22.152887Z","iopub.status.busy":"2024-09-08T13:34:22.152487Z","iopub.status.idle":"2024-09-08T13:36:31.243895Z","shell.execute_reply":"2024-09-08T13:36:31.242773Z"},"papermill":{"duration":129.430641,"end_time":"2024-09-08T13:36:31.246533","exception":false,"start_time":"2024-09-08T13:34:21.815892","status":"completed"},"tags":[]},"outputs":[],"source":["# Reserve these tokens\n","reserved_tokens = [\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\"]\n","\n","# Tokenize English samples\n","eng_samples = [text_pair[0] for text_pair in train_pairs]\n","eng_vocab = train_word_piece(eng_samples, ENG_VOCAB_SIZE, reserved_tokens)\n","\n","# Tokenize Portuguese samples\n","por_samples = [text_pair[1] for text_pair in train_pairs]\n","por_vocab = train_word_piece(por_samples, POR_VOCAB_SIZE, reserved_tokens)"]},{"cell_type":"code","execution_count":32,"id":"3a63358a","metadata":{"execution":{"iopub.execute_input":"2024-09-08T13:36:31.86973Z","iopub.status.busy":"2024-09-08T13:36:31.868998Z","iopub.status.idle":"2024-09-08T13:36:31.874448Z","shell.execute_reply":"2024-09-08T13:36:31.873545Z"},"papermill":{"duration":0.322312,"end_time":"2024-09-08T13:36:31.876456","exception":false,"start_time":"2024-09-08T13:36:31.554144","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["English tokens:  ['go', 'at', 'll', 'here', 'there', 'going', 've', 'they', 'she', 'has']\n","Portuguese tokens:  ['mary', 'do', 'mais', 'estava', '##s', 'no', 'estou', 'na', 'tem', 'foi']\n"]}],"source":["# View some tokens\n","print(\"English tokens: \", eng_vocab[100:110])\n","print(\"Portuguese tokens: \", por_vocab[100:110])"]},{"cell_type":"markdown","id":"dfa0642e","metadata":{"papermill":{"duration":0.304509,"end_time":"2024-09-08T13:36:32.48858","exception":false,"start_time":"2024-09-08T13:36:32.184071","status":"completed"},"tags":[]},"source":["#### Create tokenizers with vocabularies"]},{"cell_type":"code","execution_count":33,"id":"44479ee8","metadata":{"execution":{"iopub.execute_input":"2024-09-08T13:36:33.14938Z","iopub.status.busy":"2024-09-08T13:36:33.148638Z","iopub.status.idle":"2024-09-08T13:36:33.241556Z","shell.execute_reply":"2024-09-08T13:36:33.240561Z"},"papermill":{"duration":0.404976,"end_time":"2024-09-08T13:36:33.24379","exception":false,"start_time":"2024-09-08T13:36:32.838814","status":"completed"},"tags":[]},"outputs":[],"source":["# English tokenizer\n","eng_tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n","    vocabulary=eng_vocab,\n","    lowercase=False\n",")\n","\n","# Portuguese tokenizer\n","por_tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n","    vocabulary=por_vocab,\n","    lowercase=False\n",")"]},{"cell_type":"code","execution_count":34,"id":"71a76b5d","metadata":{"execution":{"iopub.execute_input":"2024-09-08T13:36:33.855916Z","iopub.status.busy":"2024-09-08T13:36:33.85504Z","iopub.status.idle":"2024-09-08T13:36:33.872475Z","shell.execute_reply":"2024-09-08T13:36:33.871486Z"},"papermill":{"duration":0.326135,"end_time":"2024-09-08T13:36:33.874461","exception":false,"start_time":"2024-09-08T13:36:33.548326","status":"completed"},"tags":[]},"outputs":[],"source":["# Saving tokenizers\n","# English\n","with open('tokenizer_engpor_eng.pickle', 'wb') as handle:\n","    pickle.dump(eng_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","# Portuguese\n","with open('tokenizer_engpor_por.pickle', 'wb') as handle:\n","    pickle.dump(por_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"]},{"cell_type":"code","execution_count":35,"id":"9af6a14f","metadata":{"execution":{"iopub.execute_input":"2024-09-08T13:36:34.48203Z","iopub.status.busy":"2024-09-08T13:36:34.481318Z","iopub.status.idle":"2024-09-08T13:36:34.52993Z","shell.execute_reply":"2024-09-08T13:36:34.529002Z"},"papermill":{"duration":0.35283,"end_time":"2024-09-08T13:36:34.53206","exception":false,"start_time":"2024-09-08T13:36:34.17923","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Original sentence:  she's never fallen in love.\n","Tokenized output:  tf.Tensor([ 108    9   44  145 1830   70  196   12], shape=(8,), dtype=int32)\n","Recovered text after tokenizing:  tf.Tensor(b\"she ' s never fallen in love .\", shape=(), dtype=string)\n","\n","Original sentence:  ela nunca se apaixonou.\n","Tokenized output:  tf.Tensor([ 117  155   93 2416   13], shape=(5,), dtype=int32)\n","Recovered text after tokenizing:  tf.Tensor(b'ela nunca se apaixonou .', shape=(), dtype=string)\n"]}],"source":["# Test English tokenizer on a sample\n","eng_input_eg = text_pairs[0][0]\n","eng_token_eg = eng_tokenizer(eng_input_eg)\n","print(\"Original sentence: \", eng_input_eg)\n","print(\"Tokenized output: \", eng_token_eg)\n","print(\"Recovered text after tokenizing: \", eng_tokenizer.detokenize(eng_token_eg))\n","\n","print()\n","# Test Portuguese tokenizer on a sample\n","por_input_eg = text_pairs[0][1]\n","por_token_eg = por_tokenizer(por_input_eg)\n","print(\"Original sentence: \", por_input_eg)\n","print(\"Tokenized output: \", por_token_eg)\n","print(\"Recovered text after tokenizing: \", por_tokenizer.detokenize(por_token_eg))"]},{"cell_type":"markdown","id":"714e1193","metadata":{"papermill":{"duration":0.34872,"end_time":"2024-09-08T13:36:35.187664","exception":false,"start_time":"2024-09-08T13:36:34.838944","status":"completed"},"tags":[]},"source":["### Format datasets"]},{"cell_type":"code","execution_count":36,"id":"cbdf935a","metadata":{"execution":{"iopub.execute_input":"2024-09-08T13:36:35.799841Z","iopub.status.busy":"2024-09-08T13:36:35.798909Z","iopub.status.idle":"2024-09-08T13:36:39.148388Z","shell.execute_reply":"2024-09-08T13:36:39.147565Z"},"papermill":{"duration":3.660623,"end_time":"2024-09-08T13:36:39.151107","exception":false,"start_time":"2024-09-08T13:36:35.490484","status":"completed"},"tags":[]},"outputs":[],"source":["train_ds = make_dataset(train_pairs)\n","val_ds = make_dataset(val_pairs)"]},{"cell_type":"code","execution_count":37,"id":"ea103df5","metadata":{"execution":{"iopub.execute_input":"2024-09-08T13:36:39.766518Z","iopub.status.busy":"2024-09-08T13:36:39.765609Z","iopub.status.idle":"2024-09-08T13:36:41.182361Z","shell.execute_reply":"2024-09-08T13:36:41.181259Z"},"papermill":{"duration":1.72275,"end_time":"2024-09-08T13:36:41.184595","exception":false,"start_time":"2024-09-08T13:36:39.461845","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["inputs[\"encoder_inputs\"].shape: (64, 40)\n","inputs[\"decoder_inputs\"].shape: (64, 40)\n","targets.shape: (64, 40)\n"]}],"source":["# Look at sequence shapes\n","for inputs, target in train_ds.take(1):\n","    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n","    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n","    print(f\"targets.shape: {targets.shape}\")"]},{"cell_type":"markdown","id":"db23213e","metadata":{"papermill":{"duration":0.305986,"end_time":"2024-09-08T13:36:41.808191","exception":false,"start_time":"2024-09-08T13:36:41.502205","status":"completed"},"tags":[]},"source":["## Model Construction"]},{"cell_type":"markdown","id":"83ad599a","metadata":{"papermill":{"duration":0.30023,"end_time":"2024-09-08T13:36:42.452495","exception":false,"start_time":"2024-09-08T13:36:42.152265","status":"completed"},"tags":[]},"source":["### Encoder"]},{"cell_type":"code","execution_count":38,"id":"2b443d50","metadata":{"execution":{"iopub.execute_input":"2024-09-08T13:36:43.063853Z","iopub.status.busy":"2024-09-08T13:36:43.062929Z","iopub.status.idle":"2024-09-08T13:36:43.133466Z","shell.execute_reply":"2024-09-08T13:36:43.132645Z"},"papermill":{"duration":0.377751,"end_time":"2024-09-08T13:36:43.135548","exception":false,"start_time":"2024-09-08T13:36:42.757797","status":"completed"},"tags":[]},"outputs":[],"source":["# Inputs\n","encoder_inputs = keras.Input(shape=(None,), name=\"encoder_inputs\")\n","\n","# Embedding\n","x = keras_nlp.layers.TokenAndPositionEmbedding(\n","    vocabulary_size=ENG_VOCAB_SIZE,\n","    sequence_length=MAX_SEQUENCE_LENGTH,\n","    embedding_dim=EMBED_DIM\n",")(encoder_inputs)\n","\n","# Outputs\n","encoder_outputs = keras_nlp.layers.TransformerEncoder(\n","    intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS\n",")(inputs=x)\n","\n","# Define encoder\n","encoder = keras.Model(encoder_inputs, encoder_outputs)"]},{"cell_type":"markdown","id":"675f16a5","metadata":{"papermill":{"duration":0.307482,"end_time":"2024-09-08T13:36:43.744726","exception":false,"start_time":"2024-09-08T13:36:43.437244","status":"completed"},"tags":[]},"source":["### Decoder"]},{"cell_type":"code","execution_count":39,"id":"0d78dee2","metadata":{"execution":{"iopub.execute_input":"2024-09-08T13:36:44.391865Z","iopub.status.busy":"2024-09-08T13:36:44.391133Z","iopub.status.idle":"2024-09-08T13:36:44.504831Z","shell.execute_reply":"2024-09-08T13:36:44.503801Z"},"papermill":{"duration":0.460412,"end_time":"2024-09-08T13:36:44.507048","exception":false,"start_time":"2024-09-08T13:36:44.046636","status":"completed"},"tags":[]},"outputs":[],"source":["# Inputs\n","decoder_inputs = keras.Input(shape=(None,), name=\"decoder_inputs\") # What we already predicted\n","encoded_seq_inputs = keras.Input(shape=(None, EMBED_DIM), name=\"decoder_state_inputs\") # Output from encoder to go to the next word\n","\n","# Embedding\n","x = keras_nlp.layers.TokenAndPositionEmbedding(\n","    vocabulary_size=POR_VOCAB_SIZE,\n","    sequence_length=MAX_SEQUENCE_LENGTH,\n","    embedding_dim=EMBED_DIM\n",")(decoder_inputs)\n","\n","# Decoder layer\n","x = keras_nlp.layers.TransformerDecoder(\n","    intermediate_dim=INTERMEDIATE_DIM,\n","    num_heads=NUM_HEADS\n",")(decoder_sequence=x, encoder_sequence=encoded_seq_inputs)\n","\n","# Add dropout\n","x = keras.layers.Dropout(0.5)(x)\n","\n","# Outputs\n","decoder_outputs = keras.layers.Dense(POR_VOCAB_SIZE, activation='softmax')(x)\n","\n","# Define decoder\n","decoder = keras.Model(\n","    [\n","        decoder_inputs,\n","        encoded_seq_inputs\n","    ],\n","    decoder_outputs\n",")\n","\n","decoder_outputs = decoder([decoder_inputs, encoder_outputs])"]},{"cell_type":"markdown","id":"25e8c7b9","metadata":{"papermill":{"duration":0.301213,"end_time":"2024-09-08T13:36:45.109916","exception":false,"start_time":"2024-09-08T13:36:44.808703","status":"completed"},"tags":[]},"source":["### Transformer"]},{"cell_type":"code","execution_count":40,"id":"bfceba7b","metadata":{"execution":{"iopub.execute_input":"2024-09-08T13:36:45.716863Z","iopub.status.busy":"2024-09-08T13:36:45.716446Z","iopub.status.idle":"2024-09-08T13:36:45.742151Z","shell.execute_reply":"2024-09-08T13:36:45.741257Z"},"papermill":{"duration":0.332068,"end_time":"2024-09-08T13:36:45.744424","exception":false,"start_time":"2024-09-08T13:36:45.412356","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer_eng_por\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"transformer_eng_por\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ token_and_position… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,850,240</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenAndPositionE…</span> │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ transformer_encode… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,315,072</span> │ token_and_positi… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ functional_3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">9,283,992</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">15000</span>)            │            │ transformer_enco… │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ token_and_position… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,850,240\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n","│ (\u001b[38;5;33mTokenAndPositionE…\u001b[0m │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ decoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ transformer_encode… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m1,315,072\u001b[0m │ token_and_positi… │\n","│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ functional_3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │  \u001b[38;5;34m9,283,992\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n","│ (\u001b[38;5;33mFunctional\u001b[0m)        │ \u001b[38;5;34m15000\u001b[0m)            │            │ transformer_enco… │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,449,304</span> (55.12 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,449,304\u001b[0m (55.12 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,449,304</span> (55.12 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m14,449,304\u001b[0m (55.12 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"}],"source":["transformer2 = keras.Model(\n","    [encoder_inputs, decoder_inputs],\n","    decoder_outputs,\n","    name=\"transformer_eng_por\"\n",")\n","\n","transformer2.summary()"]},{"cell_type":"code","execution_count":41,"id":"83f508a9","metadata":{"execution":{"iopub.execute_input":"2024-09-08T13:36:46.355733Z","iopub.status.busy":"2024-09-08T13:36:46.355368Z","iopub.status.idle":"2024-09-08T13:36:46.365144Z","shell.execute_reply":"2024-09-08T13:36:46.364197Z"},"papermill":{"duration":0.317535,"end_time":"2024-09-08T13:36:46.367108","exception":false,"start_time":"2024-09-08T13:36:46.049573","status":"completed"},"tags":[]},"outputs":[],"source":["# Compile transformer\n","transformer2.compile(optimizer=tf.keras.optimizers.RMSprop(),\n","                   loss='sparse_categorical_crossentropy',\n","                   metrics=['accuracy'])"]},{"cell_type":"markdown","id":"a4131cb2","metadata":{"papermill":{"duration":0.30437,"end_time":"2024-09-08T13:36:47.015123","exception":false,"start_time":"2024-09-08T13:36:46.710753","status":"completed"},"tags":[]},"source":["### Train Model"]},{"cell_type":"code","execution_count":42,"id":"3c35fa84","metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2024-09-08T13:36:47.624348Z","iopub.status.busy":"2024-09-08T13:36:47.623916Z","iopub.status.idle":"2024-09-08T13:54:03.224919Z","shell.execute_reply":"2024-09-08T13:54:03.223788Z"},"papermill":{"duration":1037.100209,"end_time":"2024-09-08T13:54:04.416247","exception":false,"start_time":"2024-09-08T13:36:47.316038","status":"completed"},"scrolled":true,"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1725802614.509576      88 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m1435/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 49ms/step - accuracy: 0.6573 - loss: 2.1079"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1725802691.086363      88 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n","I0000 00:00:1725802701.756670     533 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_115', 340 bytes spill stores, 340 bytes spill loads\n","\n","I0000 00:00:1725802706.538431     532 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_22', 864 bytes spill stores, 864 bytes spill loads\n","\n","I0000 00:00:1725802708.594204     535 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_112', 100 bytes spill stores, 100 bytes spill loads\n","\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m2118/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6662 - loss: 1.9803"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1725802749.301344      89 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n","W0000 00:00:1725802754.315891      90 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m2118/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 65ms/step - accuracy: 0.6662 - loss: 1.9801 - val_accuracy: 0.7548 - val_loss: 1.1937\n","Epoch 2/10\n","\u001b[1m2118/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 49ms/step - accuracy: 0.9276 - loss: 0.3788 - val_accuracy: 0.9964 - val_loss: 0.0260\n","Epoch 3/10\n","\u001b[1m2118/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 48ms/step - accuracy: 0.9959 - loss: 0.0297 - val_accuracy: 0.9990 - val_loss: 0.0076\n","Epoch 4/10\n","\u001b[1m2118/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 47ms/step - accuracy: 0.9990 - loss: 0.0072 - val_accuracy: 0.9996 - val_loss: 0.0034\n","Epoch 5/10\n","\u001b[1m2118/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 47ms/step - accuracy: 0.9995 - loss: 0.0040 - val_accuracy: 0.9998 - val_loss: 0.0021\n","Epoch 6/10\n","\u001b[1m2118/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 46ms/step - accuracy: 0.9998 - loss: 0.0020 - val_accuracy: 0.9999 - val_loss: 0.0013\n","Epoch 7/10\n","\u001b[1m2118/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 46ms/step - accuracy: 0.9999 - loss: 0.0013 - val_accuracy: 0.9999 - val_loss: 9.5354e-04\n","Epoch 8/10\n","\u001b[1m2118/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 46ms/step - accuracy: 0.9999 - loss: 8.1920e-04 - val_accuracy: 0.9999 - val_loss: 7.5336e-04\n","Epoch 9/10\n","\u001b[1m2118/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 45ms/step - accuracy: 0.9999 - loss: 6.0080e-04 - val_accuracy: 0.9999 - val_loss: 6.3727e-04\n","Epoch 10/10\n","\u001b[1m2118/2118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 4.6683e-04 - val_accuracy: 0.9999 - val_loss: 5.5235e-04\n"]},{"data":{"text/plain":["<keras.src.callbacks.history.History at 0x7b396cc308e0>"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["transformer2.fit(train_ds, validation_data=[val_ds],\n","               epochs=10,\n","               callbacks=[create_model_checkpoint(transformer2.name)])"]},{"cell_type":"markdown","id":"4e8b3fcc","metadata":{"papermill":{"duration":1.234645,"end_time":"2024-09-08T13:54:06.901975","exception":false,"start_time":"2024-09-08T13:54:05.66733","status":"completed"},"tags":[]},"source":["## Decoding Test Sentences"]},{"cell_type":"code","execution_count":43,"id":"82b1a523","metadata":{"execution":{"iopub.execute_input":"2024-09-08T13:54:09.405552Z","iopub.status.busy":"2024-09-08T13:54:09.404649Z","iopub.status.idle":"2024-09-08T13:54:13.798665Z","shell.execute_reply":"2024-09-08T13:54:13.797681Z"},"papermill":{"duration":5.631107,"end_time":"2024-09-08T13:54:13.800925","exception":false,"start_time":"2024-09-08T13:54:08.169818","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Example1\n","somebody tipped off the gang members to the police surveillance.\n","nhou coincidência comer é d rádio jantouferirtório éferir p terminamos fechar herói marcado consiga\n","\n","Example2\n","you're a pretty girl.\n","( para ; alguns laranja herói\n","\n"]}],"source":["# Draw English samples from test set\n","test_eng_texts = [pair[0] for pair in test_pairs]\n","\n","# Output 2 example translations\n","for i in range(2):\n","    input_sentence = random.choice(test_eng_texts)\n","    translated = decode_sequences([input_sentence], transformer2, por_tokenizer)\n","    translated = translated.numpy()[0].decode('utf-8')\n","    \n","    translated = (\n","        translated.replace(\"[PAD]\", \"\")\n","        .replace(\"[UNK]\", \"\")\n","        .replace(\"[START]\", \"\")\n","        .replace(\"[END]\", \"\")\n","        .strip()\n","    )\n","    print(f\"Example{i+1}\")\n","    print(input_sentence)\n","    print(translated)\n","    print()"]},{"cell_type":"markdown","id":"768bb939","metadata":{"papermill":{"duration":1.217531,"end_time":"2024-09-08T13:54:16.25476","exception":false,"start_time":"2024-09-08T13:54:15.037229","status":"completed"},"tags":[]},"source":["# English-Aymara"]},{"cell_type":"markdown","id":"6b538717","metadata":{"papermill":{"duration":1.18211,"end_time":"2024-09-08T13:54:18.678968","exception":false,"start_time":"2024-09-08T13:54:17.496858","status":"completed"},"tags":[]},"source":["The dataset for English to Aymara is significantly smaller (sourced from HuggingFace) and consists of specific words rather than sentences as the other datasets have. If more, higher quality data becomes available, this project will be updated."]},{"cell_type":"markdown","id":"d534604c","metadata":{"papermill":{"duration":1.289329,"end_time":"2024-09-08T13:54:21.19586","exception":false,"start_time":"2024-09-08T13:54:19.906531","status":"completed"},"tags":[]},"source":["## Setup"]},{"cell_type":"markdown","id":"db5913de","metadata":{"papermill":{"duration":1.232974,"end_time":"2024-09-08T13:54:23.650437","exception":false,"start_time":"2024-09-08T13:54:22.417463","status":"completed"},"tags":[]},"source":["### Import English-Aymara dataset"]},{"cell_type":"code","execution_count":44,"id":"e5789e4b","metadata":{"execution":{"iopub.execute_input":"2024-09-08T13:54:26.069822Z","iopub.status.busy":"2024-09-08T13:54:26.068847Z","iopub.status.idle":"2024-09-08T13:54:26.695809Z","shell.execute_reply":"2024-09-08T13:54:26.694878Z"},"papermill":{"duration":1.817004,"end_time":"2024-09-08T13:54:26.698066","exception":false,"start_time":"2024-09-08T13:54:24.881062","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Aymara</th>\n","      <th>English</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>achachi</td>\n","      <td>grandfather</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>achachila</td>\n","      <td>grandfather</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>achachilan tatapa</td>\n","      <td>great grandfather</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>achacu</td>\n","      <td>mouse</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>achaku</td>\n","      <td>mouse</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              Aymara            English\n","0            achachi        grandfather\n","1          achachila        grandfather\n","2  achachilan tatapa  great grandfather\n","3             achacu              mouse\n","4             achaku              mouse"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["eng_aym = pd.read_csv(\"hf://datasets/alvations/aymara-english/aymara-english.tsv\", sep=\"\\t\")\n","eng_aym.head()"]},{"cell_type":"code","execution_count":null,"id":"7144f00a","metadata":{"papermill":{"duration":1.248436,"end_time":"2024-09-08T13:54:29.173189","exception":false,"start_time":"2024-09-08T13:54:27.924753","status":"completed"},"tags":[]},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5611402,"sourceId":9272285,"sourceType":"datasetVersion"}],"dockerImageVersionId":30762,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"papermill":{"default_parameters":{},"duration":1839.55386,"end_time":"2024-09-08T13:54:33.872298","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-09-08T13:23:54.318438","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}